---
title: "Glacial area"
subtitle: "[NO_GLAC_001]"
format: 
  html:
    embed-resources: true
    code-fold: true
    toc: true
    toc-title: Contents
    toc-depth: 3
    smooth-scroll: true
execute: 
  cache: true
author:
  - name: Anders L. Kolstad
    email: anders.kolstad@nina.no
    affiliations:
      - id: myID
        name: Norwegian Institute for Nature Research 
date: March 5, 2025
callout-icon: false
lightbox: true
css: ../../../style.css
code-links:
      - text: Add a review
        icon: github
        href: https://github.com/NINAnor/ecRxiv
bibliography: references.bib
---

<!--# This is a template for how to document the indicator analyses. Make sure also to not change the order, or modify, the headers, unless you really need to. This is because it easier to read if all the indicators are presented using the same layout. If there is one header where you don't have anything to write, just leave the header as is, and don't write anything below it. If you are providing code, be careful to annotate and comment on every step in the analysis. Before starting it is recommended to fill in as much as you can in the metadata file. This file will populate the initial table in your output.-->

<!--# Load all you dependencies here -->

```{r setup}
#| include: false
library(knitr)
library(tidyverse)
library(kableExtra)
library(here)
library(sf)
library(ggridges)
library(ggpubr)
knitr::opts_chunk$set(echo = TRUE)
path <- here::here("indicators/NO_GLAC_001")
```

```{r source}
#| echo: false
source(here::here("_common.R"))
```

```{r}
#| echo: false
meta <- readxl::read_xlsx("../metadata.xlsx")
st <- meta |>
  filter(Variable == "status") |>
  pull(Value)
version <- meta |>
  filter(Variable == "Version") |>
  pull(Value)
auth <- meta |>
  filter(Variable == "authors") |>
  pull(Value)
year <- meta |>
  filter(Variable == "yearAdded") |>
  pull(Value)
id <- meta |>
  filter(Variable == "indicatorID") |>
  pull(Value)
name <- meta |>
  filter(Variable == "indicatorName") |>
  pull(Value)
url <- meta |>
  filter(Variable == "url") |>
  pull(Value)

meta <- meta |>
  mutate(Variable = case_match(Variable,
    "indicatorID" ~ "Indicator ID" ,
    "indicatorName" ~ "Indicator Name",
    "country" ~ "Country",
    "continent" ~ "Continent",
    "ECT" ~ "Ecosystem Condition Typology Class",
    "yearAdded" ~ "Year added",
    "yearLastUpdate" ~ "Last update",
    .default = Variable
   )
  ) |>
  filter(Variable != "authors")

```

<!--# The following parts are autogenerated. Do not edit. -->

```{r}
#| echo: false
#| results: asis
status(st)
```

::: {layout-ncol="2"}
> **Recomended citation**: `r paste(auth, " ", year, ". ", name, " (ID: ", id, ") ", "v. ", version, ". ecRxiv: ", url, sep="")`

> **Version**: `r version`
:::

```{=html}
<details>
<summary>Show metadata</summary>
```

```{r tbl-meta}
#| tbl-cap: 'Indicator metadata'
#| echo: false
#| warning: false

meta |>
  select(Variable, Value) |>
  kbl(col.names = NULL) 

```

</details>

::: {.callout-tip collapse="true"}
## Logg

<!--# Update this logg with short messages for each update -->

-   01 Jan. 1901 - Original PR
:::

<hr />

<!--# Document you work below.  -->

## 1. Summary


Glaciers represents both an important structural element in alpine ecosystems, providing melt water and local climate control. It is also a unique nature type in itself, with few, but very specialised, species living on or in association with the ice. Glaciers are permanently ice covered areas and they are sensitive to climate change, especially climate warming, which melts the ice. In Norway we have a rather detailed and precise map of the glacial extent from the period 1947-1985. Here we use this data as a representation of the climatic reference condition (pre climate warming), and compare the glacial extent with an update glacial extent map from 2018-2019 to create a normalised ecosystem condition indicator. The ecosystem assets are defined as intersections of bioclimatic regions and geographical regions. We have defined a threshold value (X~60~) as 10% remaining area, based on the assumption from Island Biogeography Theory that further loss of area will result in \>10% local species extinctions.

Indicator uncertainty originates from two sources. Firste we introduce a 3% error in the glacial estimates, based on the reported uncertainties in the mapping method. In practice we assign a probability distribution, rather than a point estimate, to each EA. We then resample the probability distributions for each EA 1000 times, creating 1000 estimates for the spatially aggregated indicator value. This introduces the second type of uncertainty, which is the spatial variation in indicator values across EAs.

The indicator is ready to be used. Future updates will require new maps of glacial extent in Norway, which is highly possible to produce from satellite imagery.

Interpretation: The indicator value represents the mean remaining glacial area across EAs.

Workflow

1.  Import glacial extent maps from two time periods

2.  Import delineations for bioclimatic regions and geographical regions and intersect to create strata (ecosystem assets, EA)

3.  Import alpine ecosystem mask

4.  Compile spatial dataset where each EA has data on strata category, glacial area at two time points and total mountain area.

5.  Add 3% uncertainty to glacial extent estimates

6.  Normalise variable at EA level by scaling, transforming and truncating.

7.  Resample within EAs and create a distribution of 1000 estimates of a spatially aggregate indicator value for geographical regions. Di this using two weighting schemes for comparison: weighted based on total mountain area or initial glacial area within each EA.

8.  Aggregate spatially from geographical region to national level, also using bootstrapping.

9.  Summarise national estimate and 50%CI in a table

## 2. About the underlying data

<!--# Describe the data you have used in more detail, it's origin, biases, availabilit ect.-->

### 2.1 Spatial and temporal resolution and extent

<!--# Describe the temporal and spatial resolution and extent of the data used -->

### 2.2 Original units

<!--# What are the original units for the most relevant  variables in the data-->

### 2.3 Additional comments about the dataset

<!--# Text here -->

#### 2.3.1 Instructions for citing, using and accessing data

<!--# Is the data openly available? If not, how can one access it? What are the key references to the datasets?   -->

The glaciel extent maps are distributed under CC-BY 4.0. We have made a simplified (less columns) version of the dataset available on github in order to make the workflow more reproducible.

## 3. Indicator properties

### 3.1 Ecosystem Condition Typology Class (ECT)


Area of glaciers is categorised as describing a C1 - Landscape and seascape characteristic. This put emphasis in the role of glaciers as a unique habitat type and a structural element in alpine ecosystems. The indicator has previously been attributed to A1 - Physical state characteristics due to the importance of melt water.

### 3.2 Ecosystem condition characteristic


### 3.3 Other standards

<!--# Optional: Add text about other spesific standards, e.g. national standards, and how the indicator relates to these -->

### 3.4 Collinearities with other indicators

<!--# Describe known collinearities with other metrices (indicators or variables) that could become problematic if they were also included in the same Ecosystem Condition Assessment as the indicator described here. -->

### 3.5 Impact factors

<!--# Describe the main natural and anthropogenic factors that affecst the metric -->

## 4. Reference condition and levels

### 4.1 Reference condition

<!--# Define the reference condition (or refer to where it is defined). Note the destinction between reference condition and reference levels 10.3897/oneeco.5.e58216  -->

### 4.2 Reference levels

```{=html}
<!--# 

If relevant (i.e. if you have normalised a variable), describe the reference levels used to normalise the variable. 

Use the terminology where X~0~ referes to the referece level (the variable value) denoting the worst possible condition; X~100~denotes the optimum or best possible condition; and X~*n*~, where in is between 0 and 100, denotes any other anchoring points linking the variable scale to the indicator scale (e.g. the threshold value between good and bad condition X~60^). 

Why was the current option chosen and how were the reference levels quantified? If the reference values are calculated as part of the analyses further down, please repeat the main information here.

 -->
```

#### 4.2.1 Spatial resolution and validity

```{=html}
<!--# 

Describe the spatial resolution of the reference levels. E.g. is it defined as a fixed value for all areas, or does it vary. Also, at what spatial scale are the reference levels valid? For example, if the reference levels have a regional resolution (varies between regions), it might mean that it is only valid and correct to use for normalising local variable values that are first aggregated to regional scale. However, sometimes the reference levels are insensitive to this and can be used to scale variables at the local (e.g. plot) scale. 

 -->
```

## 5. Uncertainties

<!--# Describe the main uncertainties or sources of error in the indicator or the underlying data. -->

## 6. References

<!--# You can add references manually or use a citation manager and add intext citations as with crossreferencing and hyperlinks. See https://quarto.org/docs/authoring/footnotes-and-citations.html -->

## 7. Datasets

<!--# Describe the unique datasets seperately under seperate headers (Dataset A, Dataset B, etc.-->

### 7.1 Dataset A - Glacial extent 1947-1985

This data is based on a combination of landsat imagery and digitized topographic maps [@winsvold2014]. We use this map as our reference condition and assume this glacial extent represents the climatic period 1961-1990.

The dataset is manually downloaded.

URL: https://nve.brage.unit.no/nve-xmlui/handle/11250/2831053

```{r import1}
#| eval: false
#| code-summary: "Structure and cache historic glacier data"
path1 <- paste0(path, "/data/cryoclim_GAO_NO_1947_1985_UTM_33N/cryoclim_GAO_NO_1947_1985_UTM_33N.shp")
dat_old <- sf::read_sf(path1) |>
  select(areal_km2)
saveRDS(dat_old, paste0(path, "/data/glacial_extent_old.rds"))
```

```{r readCache1}
#| code-summary: "Read data"
dat_old <- readRDS(paste0(path, "/data/glacial_extent_old.rds"))
```

### 7.2 Dataset B - Glacial extent 2018-2019

This is the map of glacial extent measured in ther period 2018-2019 [@andreassen2022].

URL: https://nve.brage.unit.no/nve-xmlui/handle/11250/2836926

```{r import2}
#| eval: false
#| code-summary: "Structure and cache modern glacier data"
path2 <- paste0(path, "/data/GlacierAreaOutline_NO_2018_2019_N/GlacierAreaOutline_2018_2019_N.shp")

dat_new <- sf::read_sf(path2) |>
  select(areal_km2)
saveRDS(dat_new, paste0(path, "/data/glacial_extent_new.rds"))
```

```{r readCache2}
#| code-summary: "Read data"
dat_new <- readRDS(paste0(path, "/data/glacial_extent_new.rds"))
```

### 7.3 Dataset C - Geographical regions


```{r greg}
#| code-fold: true
#| code-summary: "Importing geographical regions"

greg <- readRDS(paste0(path, "/data/regions.rds")) |>
  mutate(region = case_when(
    id == 3 ~ "Oestlandet",
    .default = region
  ))

```

### 7.4 Dataset D - Bioclimatic regions

Here I import a map dataset of bioclimatic sones and sections for Norway [@bakkestuen2008]. The data licence is unknown, but we have the authors permission to use the data (Bakkestuen, *pers. com.*). There is, however, a [public WMS service](https://kartkatalog.geonorge.no/metadata/66f09e22-23a4-43c6-a0df-426d2b317890), but I don't known if the data is downloadable anywhere.

I combine the sones (related to heat sums and the north-south gradient) and sections (related to oceanity and the west-east gradient) into regions. There are 24 regions, but I will combine some sones and sections to reduce this amount. Since there are few glaciers in continental areas I will combine sections 4 and 5, since we don't need that high resolution in the EAs here. Similarly, I will combine the warmer sones 1 and 2.

```{r}
#| eval: false

# file path to locally stored data
pathD <- "R:/GeoSpatialData/BiogeographicalRegions/Norway_PCA_klima/Original/20170614_Bioklima/20170614_Bioklima.gdb"

# read in the data and convert to tibbles for easy joins
soner <- sf::read_sf(pathD, layer = "Soner2017") |> 
  as_tibble() |>
  mutate(Sone = case_when(
    Sone_kode %in% c("6SO-1", "6SO-2") ~ "6SO-1-2",
    .default = Sone_kode
  ))

# unique(soner2$Sone)

seksjoner <- sf::read_sf(pathD, layer = "Seksjoner2017") |> 
  as_tibble() |>
  mutate(Seksjon = case_when(
    Seksjon_ko %in% c("6SE-4", "6SE-5") ~ "6SE-4-5",
    .default = Seksjon_ko
  ))

# unique(seksjoner$Seksjon)

# join based on SSB IDs and convert to sf object again
BCreg <- dplyr::left_join(soner , seksjoner |> select(-Shape), by = join_by(SSBID)) |>
  mutate(BCregion = paste(Seksjon, Sone)) |>
  sf::st_as_sf() |>
  select(SSBID,
  Sone,
  Seksjon,
  BCregion) |>
  st_transform(st_crs(greg))

```


```{r makeFig}
#| eval: false
#| code-summary: 'Make figure'
BCreg |>
  ggplot(aes(x = Sone, fill = BCregion)) +
  geom_bar() +
  facet_grid(Seksjon ~ Sone, scales = "free") +
  guides(fill = "none") +
  theme(axis.text.x = element_blank(),
    axis.title.x.bottom = element_blank()) +
  labs(y = "km-2")
ggsave("../img/bcreg.png")
```

```{r fig-sonerOgSeksjoner}
#| fig-cap: "Distribution of area within each combination of bioclimatic sone and section (i.e. each bioclimatic region)."

knitr::include_graphics("../img/bcreg.png")
```



```{r}
#| eval: false
#| code-fold: true
#| code-summary: "Union and cache bioclimatic region data"

BCreg <- BCreg |>
  group_by(BCregion) |>
  summarize(Shape = st_union(Shape))
saveRDS(BCreg, paste0(path, "/data/bioclimatic_regions.rds"))
```

```{r}
#| include: false
# read cache
BCreg <- readRDS(paste0(path, "/data/bioclimatic_regions.rds"))
```

### 7.5 Dataset E - Alpine ecosystem extent


<!-- This extent map might be updated in the near future. I am not sure the origin of this map. Check the ECA rapport. -->

```{r}
#| eval: false
#| code-fold: true
#| code-summary: "Prepare and cache alpine extent map"

pathE <- paste0(path, "/data/temp/alpine_extent.tif")

alpine <- stars::read_stars(pathE) |>
  st_as_sf(merge = T)

# intersections are much quicker on multipolygons, so I will union the geometries. 
alpine <- st_union(alpine)

saveRDS(alpine, paste0(path, "/data/alpine_extent.rds"))
```

```{r}
#| include: false
alpine <- readRDS(paste0(path, "/data/alpine_extent.rds"))
```


## 8. Spatial units



### 8.1 Ecosystem assets (EA)
Next we need to create a dataset for the EAs. The EAs will be defined as the intersection between bioclimatic regions and geographical regions

```{r}
#| eval: false
#| code-summary: 'Create EA dataset'
EA <- BCreg |>
  sf::st_intersection(greg)

# create new variable for the unique EA IDs
EA <- EA |>
  mutate(EA_ID = row_number())

saveRDS(EA, paste0(path, "/data/EAs.rds"))
```

```{r}
#| include: false
EA <- readRDS(paste0(path, "/data/EAs.rds"))
```

Then we add total mountain area and glacier area as variables to the EA dataset.

```{r mountainArea}
#| warning: false
#| code-summary: 'Intersect EAs and alpine extent map'

# get mountain area for each EA 
temp_alpine <- EA |>
  st_intersection(alpine) |>
  mutate(mountainArea = units::drop_units(st_area(Shape))) |>
  as_tibble()

#temp_alpine |>
#  group_by(BCregion) |>
#  summarise(area = sum(mountainArea)) |>
#  ggplot(aes(x = fct_reorder(BCregion, area), y = area)) +
#  geom_col() +
#  labs(x = "Bioclimatic region",
#       y = "Total mountain area (m2)") +
#  coord_flip()+
#  theme_bw()

```


```{r calcCurrent}
#| eval: false
#| code-summary: 'Intersect EAs and glacier maps'
# This code block is a bit slow to run. 1 minute maybe.
dat_new_union <- st_union(dat_new)
dat_old_union <- st_union(dat_old)

temp_new <- EA |>
  st_intersection(dat_new_union) |>
  mutate(glacierAreaCurrent = units::drop_units(st_area(Shape))) |>
  as_tibble()

temp_old <- EA |>
  st_intersection(dat_old_union) |>
  mutate(glacierAreaOld = units::drop_units(st_area(Shape))) |>
  as_tibble()

saveRDS(dat_new_union, paste0(path, "/data/temp/dat_new_union.rds"))
saveRDS(dat_old_union, paste0(path, "/data/temp/dat_old_union.rds"))
saveRDS(temp_new, paste0(path, "/data/temp/temp_new.rds"))
saveRDS(temp_old, paste0(path, "/data/temp/temp_old.rds"))
```

```{r}
#| include: false

dat_new_union <- readRDS(paste0(path, "/data/temp/dat_new_union.rds"))
dat_old_union <- readRDS(paste0(path, "/data/temp/dat_old_union.rds"))
temp_new <- readRDS(paste0(path, "/data/temp/temp_new.rds"))
temp_old <- readRDS(paste0(path, "/data/temp/temp_old.rds"))
```


```{r join}
#| code-summary: 'Add glacier and mountain extent to EA dataset' 
EA <- EA |>
  as_tibble() |>
  left_join(
    temp_new |> select(
      glacierAreaCurrent,
      EA_ID
    ),
    by = join_by(EA_ID)
  ) |>
  left_join(
    temp_old |> select(
      glacierAreaOld,
      EA_ID
    ),
    by = join_by(EA_ID)
  ) |>
  left_join(
    temp_alpine |> select(
      mountainArea,
      EA_ID
    ),
    by = join_by(EA_ID)
  ) |>
  st_as_sf()

```

We see from @fig-area that glaciers are rare in sections 4 and 5 (good reason for combining them), and sone 1-3. We could perhaps have combined sone 3 along with sones 1 and 2, but it makes little difference.
@fig-arealUnits show the summed glacial area for different spatial units. 

```{r fig-area}
#| fig-cap: 'The extent of glacier and total mountain area for each geographical region (top), bioclimatic section (middle) and sone (bottom). The area for mountains is divided by 100 to get it on the same scale as glacier area for comparisons across regions.'
#| code-summary: 'Make figure'
myVars <- c("Current",
            "Historic",
            "Mountains"
            )

one <- EA |>
  as_tibble() |>
  group_by(region) |>
  summarise(Current = sum(glacierAreaCurrent, na.rm = T),
            Historic = sum(glacierAreaOld, na.rm = T),
            Mountains = sum(mountainArea, na.rm = T)/100) |>
  pivot_longer(cols = all_of(myVars),
               names_to = "Variable",
               values_to = "Area") |>
  ggplot(aes(fill = Variable, 
             y = Area,
             x = region)) +
  geom_col(position = "dodge") +
  labs(x = "Geographical region",
       y = "Areal extent (m2) (divided by 100 in the case of mountain area)") +
  coord_flip()+
  theme_bw()

two <- EA |>
  as_tibble() |>
  mutate(seksjon = str_split_i(BCregion, " ", 1),
         sone = str_split_i(BCregion, " ", 2)) |>
  group_by(seksjon) |>
  summarise(Current = sum(glacierAreaCurrent, na.rm = T),
            Historic = sum(glacierAreaOld, na.rm = T),
            Mountains = sum(mountainArea, na.rm = T)/100) |>
  pivot_longer(cols = all_of(myVars),
               names_to = "Variable",
               values_to = "Area") |>
  ggplot(aes(fill = Variable, 
             y = Area,
             x = seksjon)) +
  geom_col(position = "dodge") +
  labs(x = "Section",
       y = "Areal extent (m2) (divided by 100 in the case of mountain area)") +
  coord_flip()+
  theme_bw()


three <- EA |>
  as_tibble() |>
  mutate(seksjon = str_split_i(BCregion, " ", 1),
         sone = str_split_i(BCregion, " ", 2)) |>
  group_by(sone) |>
  summarise(Current = sum(glacierAreaCurrent, na.rm = T),
            Historic = sum(glacierAreaOld, na.rm = T),
            Mountains = sum(mountainArea, na.rm = T)/100) |>
  pivot_longer(cols = all_of(myVars),
               names_to = "Variable",
               values_to = "Area") |>
  ggplot(aes(fill = Variable, 
             y = Area,
             x = sone)) +
  geom_col(position = "dodge") +
  labs(x = "Sones",
       y = "Areal extent (m2) (divided by 100 in the case of mountain area)") +
  coord_flip()+
  theme_bw()


ggpubr::ggarrange(one, two, three, ncol= 1)

```



```{r figCurrent}
#| code-summary: 'Make maps A and B'

map1 <- EA |>
  mutate(glacierAreaCurrent = replace_na(glacierAreaCurrent, 0)) |>
  ggplot() +
  geom_sf(aes(fill = glacierAreaCurrent),
    colour = NA,
    show.legend = F
  ) +
  scale_fill_gradient(low = "skyblue", high = "dodgerblue4")  

map2 <- ggplot()+
  geom_sf(data = greg,
    fill = "skyblue",
    colour = NA) +
  geom_sf(data = dat_new,
    fill = "dodgerblue4",
    colour = NA)

# ggpubr::ggarrange(map1, map2, labels="AUTO")

```


### 8.2 Alternative EAs

In order to test the influence of the modifiable area unit problem (MAUP), 
I will define two alternative EAs, meaning two alternative minimum mapping units: 
geographical region (greg), and country (EAA).

We also use the greg dataset as intermediate data when we aggregate from EAs to EAA.

#### 8.2.1 greg and EEA

```{r greg}
#| code-fold: true
#| code-summary: "Create greg dataset"
#| warning: false

# add id column
greg <- greg |>
  mutate(greg_ID = row_number())

# intersect with maps to get extents per geographic regoin
temp_alpine_2 <- greg |>
  st_intersection(alpine) |>
  mutate(mountainArea = units::drop_units(st_area(geometry))) |>
  as_tibble()
temp_new_2 <- greg |>
  st_intersection(dat_new_union) |>
  mutate(glacierAreaCurrent = units::drop_units(st_area(geometry))) |>
  as_tibble()
temp_old_2 <- greg |>
  st_intersection(dat_old_union) |>
  mutate(glacierAreaOld = units::drop_units(st_area(geometry))) |>
  as_tibble()

# Add data into greg dataset
greg <- greg |>
  as_tibble() |>
  left_join(
    temp_new_2 |> select(
      glacierAreaCurrent,
      greg_ID
    ),
    by = join_by(greg_ID)
  ) |>
  left_join(
    temp_old_2 |> select(
      glacierAreaOld,
      greg_ID
    ),
    by = join_by(greg_ID)
  ) |>
  left_join(
    temp_alpine_2 |> select(
      mountainArea,
      greg_ID
    ),
    by = join_by(greg_ID)
  ) |>
  st_as_sf()

```

```{r EAAcreate}
#| code-fold: true
#| code-summary: "Create EEA dataset"
#| warning: false

# and the same for EAA
EAA <- readRDS(paste0(path, "/data/norway.rds")) |>
  add_column(EAA_ID = "1")


# I could get these area sums easier, but here I just copy over the method from above
temp_alpine_3 <- EAA |>
  st_intersection(alpine) |>
  mutate(mountainArea = units::drop_units(st_area(geometry))) |>
  as_tibble()
temp_new_3 <- EAA |>
  st_intersection(dat_new_union) |>
  mutate(glacierAreaCurrent = units::drop_units(st_area(geometry))) |>
  as_tibble()
temp_old_3 <- EAA |>
  st_intersection(dat_old_union) |>
  mutate(glacierAreaOld = units::drop_units(st_area(geometry))) |>
  as_tibble()

# Add data into EA_v3 dataset
EAA <- EAA |>
  as_tibble() |>
  left_join(
    temp_new_3 |> select(
      glacierAreaCurrent,
      EAA_ID
    ),
    by = join_by(EAA_ID)
  ) |>
  left_join(
    temp_old_3 |> select(
      glacierAreaOld,
      EAA_ID
    ),
    by = join_by(EAA_ID)
  ) |>
  left_join(
    temp_alpine_3 |> select(
      mountainArea,
      EAA_ID
    ),
    by = join_by(EAA_ID)
  ) |>
  st_as_sf()

```


```{r fig-arealUnits}
#| fig-cap: 'Current glacier extent, either as the actuall occurences (A); the the summed area per ecosystem asset (B); the summed area per gegrapical region (C); or across the entire country (D). The legend is omitted for simplicity. The point here is simply to illustrate the sizes of the different spatial units, and how the minimum mapping unit affects the information the maps.'
#| warning: false
#| fig-height: 10
#| fig-width: 8
#| code-summary: 'Make maps C and D and plot'

map3 <- greg |>
  mutate(glacierAreaCurrent = replace_na(glacierAreaCurrent, 0)) |>
  ggplot() +
  geom_sf(aes(fill = glacierAreaCurrent),
    colour = NA,
    show.legend = F
  ) +
  scale_fill_gradient(low = "skyblue", high = "dodgerblue4")




map4 <- EAA |>
  #mutate(glacierAreaCurrent = replace_na(glacierAreaCurrent, 0)) |>
  ggplot() +
  geom_sf(aes(fill = glacierAreaCurrent),
    colour = NA,
    show.legend = F
  ) +
  scale_fill_gradient(low = "skyblue", high = "dodgerblue4")


ggpubr::ggarrange(
  map2, map1,  
  map3, map4, 
  labels="AUTO")

```


## 9. Analyses

Now we go on to calcuate indicator values for the EAs, and then spatially aggregating them.

### 9.1 Calculating indicator values (distributions) for the EAs

The next steps are a follows: 

1. Add 3% methodological uncertainty to the data at the EA level by sampling
n numbers from a normal distribution with sd = mean*0.03.
1. Normalise the variable (now a prob. dist.) at the EA level using a piecewise linear transformation.
1. Aggreate to next spatial level by sampling each probability distribution with n scaled to the area weights. Try different area weightings, both by total montain area and initial glacial area.
1. Aggregate one more time to national level.
1. Repeat for two alternative _entry points_, using either geographical region or the EEA as alternative EAs.


The papers describing the galcier extent data report an estimated 3% uncertainty with their method [@andreassen2022].
I assume this to mean the standard deviation is 3% of the mean. 
I start by replacing the point estimates in each EA (and alternative EAs) 
with a probability function centered on the point estimate, and with sd = mean * 0.03.
In ecosystem accounting it is not common to allow uncertainty in the reference levels,
but here it is quite easy to implement, and I therefore see no reason not to.

```{r}
#| warning: false
#| code-fold: true
#| code-summary: "Replace estimates with prob. distributions"

EA <- EA |>
  # adding 3% uncertainty
  rowwise() |>
  mutate(
    glacierAreaCurrent_dist = 
      if_else(!is.na(glacierAreaCurrent),
              list(rnorm(1000, glacierAreaCurrent, glacierAreaCurrent*0.03)),
              NA), 
    glacierAreaOld_dist = 
      if_else(!is.na(glacierAreaOld),
              list(rnorm(1000, glacierAreaOld, glacierAreaOld*0.03)),
              NA))

```

Then we normalise, using a piecewise linear transformation, and get similar probability distribution for indicator values.
@tbl-normalise shows the dataset with indicator values (just the median value) at the EA level. 
Also in that dataset are the actuall indicator probability distributions, which can be sampled.

```{r tbl-normalise}
#| tbl-cap: 'Table of ecosystem assets, with variable values, X100 values (glacier area 1947-1985), indicator values and quartiles.'
#| code-fold: true
#| code-summary: "Normalise variable"


# create a temporary dataframe
EAtemp <- EA |>
  as_tibble() |>
  # unlist and create new rows for each random pair of current and old glacier area estimate
  unnest_longer(c(
    glacierAreaCurrent_dist,
    glacierAreaOld_dist), 
    keep_empty = T) |>
  rename(variable = glacierAreaCurrent_dist, 
         x100 = glacierAreaOld_dist) |>
  mutate(
    # define x60 value
    x60 = x100*0.1,
    # normalise using piecewise linear transfomation
    indicator =  ifelse(
      variable < x60, 
        ((variable - 0)/(x60 - 0)) * 0.6, 
        ((variable - x60)/(x100 - x60)) * (1 - 0.6) + 0.6),
    # truncate
    indicator = case_when(
      indicator > 1 ~ 1,
      indicator < 0 ~ 0,
      .default = indicator
    )) |>
  # recast into list column
  drop_na(indicator) |>
  group_by(EA_ID) |>
  summarise(indicator_dist = list(indicator), .groups = "drop")

# we then paste these distributions back into the EA object

EA <- EA |>
  as_tibble() |>
  # simplify datafra by removing some columns...
  select(-glacierAreaCurrent_dist,
         -glacierAreaOld_dist,
         -GID_0,
         -NAME_0) |>
  # add the probability distribution of indicator values
  left_join(
    EAtemp,
    by = join_by(EA_ID)
  ) |>  
  # summarise the distribution
  rowwise() |>
  mutate(
    indicator = ifelse(
      !is.null(indicator_dist),
      median(unlist(indicator_dist)),
      NA),
  # add first and third quartile
    indicator_Q1 = ifelse(
      !is.null(indicator_dist),
      quantile(unlist(indicator_dist), probs = 0.25),
      NA), 
    indicator_Q3 = ifelse(
      !is.null(indicator_dist),
      quantile(unlist(indicator_dist), probs = 0.75),
      NA), 
  ) |>
  st_as_sf()

DT::datatable(EA |>
  as_tibble() |>
  mutate(across(where(is.numeric), ~ round(.x, digits = 2))) |>
  select(
    EA_ID,
    glacierAreaCurrent,
    X100 = glacierAreaOld,
    mountainArea,
    indicator,
    indicator_Q1,
    indicator_Q3
  ))
```




### 9.2 Aggregating to geographical regions

Now we will spatially aggregate the indicator values to the level of geographic region.
We do this by sampling the probability distributions of each EA proportional to the weight.
As the weight, we we use the X~100~ value, i.e. the initial glacial area. 
EAs with no glaciers in them get NA, and are not included in the aggregated value.

For comparison, we also calcuate the aggregated values using mountain area (_mtArea_) as alternative weights, 
and we refer to these indicator values with a _mtArea_ suffix. 
We also try an approach where we calculate indicator values for geographical regions or EAA level directly, 
that is to say, without using the original EAs at all. These indicator values get a _level2_ or _level3_ suffix, respectively.

@tbl-gregAgg shows is the indicator values for the geographical regions. 
The estimates differ quite a lot depending onthe weights used, which we also see in @fig-ridgde1.

```{r gregAggx}
#| code-fold: true
#| code-summary: "Aggregate from EA to geographical region"

# In order to control the n for how many samples we draw,
# we first calculate the summed area of glaciers and mountains

#EA |>
#  as_tibble() |>
#  summarise(total_m2 = sum(glacierAreaOld, na.rm=T)) |> 
#  pull(total_m2)
## Resul: 3 327 251 347. We can divide this by 10^4

#EA |>
#  as_tibble() |>
#  #ungroup() |>
#  summarise(total_m2 = sum(mountainArea, na.rm=T)) |> 
#  pull(total_m2)
## Result: 323 871 072 604. We can divide this by 10^6


## 
EA_to_greg <- ungroup(EA) |>
  drop_na(indicator) |>
  group_by(EA_ID, region) |>
  # sample with weights
  reframe(
    indicator = 
      list(
        sample(
          unlist(indicator_dist),
          size = glacierAreaOld*10^-4,
          replace = T)),
    indicator_mtArea = 
      list(
        sample(
          unlist(indicator_dist),
          size = mountainArea*10^-6,
          replace = T))
  ) |>
  # concactenate the weighted samples
  group_by(region) |>
  summarise(indicator_dist = list(unlist(indicator)),
            indicator_mtArea_dist = list(unlist(indicator_mtArea))) |>
  # get summary values
  ungroup() |>
  rowwise() |>
  mutate(
    indicator = ifelse(
      !is.null(indicator_dist),
      median(unlist(indicator_dist)),
      NA),
  # add first and third quartile
    indicator_Q1 = ifelse(
      !is.null(indicator_dist),
      quantile(unlist(indicator_dist), probs = 0.25),
      NA), 
    indicator_Q3 = ifelse(
      !is.null(indicator_dist),
      quantile(unlist(indicator_dist), probs = 0.75),
      NA),
  # add the same for indicator_mtArea
    indicator_mtArea = ifelse(
      !is.null(indicator_mtArea_dist),
      median(unlist(indicator_mtArea_dist)),
      NA),
  # add first and third quartile
    indicator_mtArea_Q1 = ifelse(
      !is.null(indicator_mtArea_dist),
      quantile(unlist(indicator_mtArea_dist), probs = 0.25),
      NA), 
    indicator_mtArea_Q3 = ifelse(
      !is.null(indicator_mtArea_dist),
      quantile(unlist(indicator_mtArea_dist), probs = 0.75),
      NA)
  )


```



```{r createRidgePlot}
#| eval: false
#| code-fold: true
#| code-summary: "Create ridge plot"

# set bandwidth
bw <- 0.015

oneRidge <- EA_to_greg |>
  unnest_longer(indicator_dist) |>
  ggplot(aes(x = indicator_dist,
             y = region)) +
  geom_density_ridges(
         fill = "skyblue",
         bandwidth = bw) +
  labs(y = "",
       x = "Indicator values")+
  xlim(.55, 1)

twoRidge <- EA_to_greg |>
  unnest_longer(indicator_mtArea_dist) |>
  ggplot(aes(x = indicator_mtArea_dist,
             y = region)) +
  geom_density_ridges(
         fill = "lightgreen",
         bandwidth = bw) +
  labs(y = "",
       x = "Indicator values (alternative weights)")+
  xlim(.55, 1)

# ggpubr::ggarrange(oneRidge, twoRidge, ncol=1, labels = "auto")  

```


Now I add the spatially aggregated indicator values to the sf object with the 
geographical regions so that we can make a map.

```{r}
#| code-fold: true
#| code-summary: "Add indicators to greg dataset with the regional delineations"

greg <- greg |>
  as_tibble() |>
  left_join(EA_to_greg, by = join_by(region)) |>
  st_as_sf()
```


### 9.3. Alternative EAs {#sec-ea2}

What if we used different spatial units as the EAs. 
Now I calculate the indicator value directly to the geographical regions. 
This indicator will be named `indicator_level2` in the code.
As we see from @fig-ridgde1 this creates smoother density plots. 
In fact they are perfect gaussian distributions, since the 3% error was added 
to the summed glacier area for the regions,
and not on the initial glacier polygons, 
which would also be a valid approach, but it would require a lot more memory.. 
We also see that the probabilities generally match up well with the pane a and the 
original weighting scheme.
But comparing @tbl-gregAgg and @tbl-normaliseGreg we see that the point estimates are not identical,
meaning that the two approaches are not perfectly commutative, and that some other dataset could give bigger (or smaller) differences between the two approaches than what se see here.

```{r}
#| code-fold: true
#| code-summary: "Replace glacier estimates with probability distributions"

greg <- greg |>
# adding 3% uncertainty
  rowwise() |>
  mutate(
    glacierAreaCurrent_dist = 
      if_else(!is.na(glacierAreaCurrent),
              list(rnorm(1000, glacierAreaCurrent, glacierAreaCurrent*0.03)),
              NA), 
    glacierAreaOld_dist = 
      if_else(!is.na(glacierAreaOld),
              list(rnorm(1000, glacierAreaOld, glacierAreaOld*0.03)),
              NA))
```

```{r}
#| code-fold: true
#| code-summary: "Estimate indicator_level2"

# create a temporary dataframe
greg_temp <- greg |>
  as_tibble() |>
  # unlist and create new rows for each random pair of current and old glacier area estimate
  unnest_longer(c(
    glacierAreaCurrent_dist,
    glacierAreaOld_dist), 
    keep_empty = T) |>
  rename(variable = glacierAreaCurrent_dist, 
         x100 = glacierAreaOld_dist) |>
  mutate(
    # define x60 value
    x60 = x100*0.1,
    # normalise using piecewise linear transfomation
    indicator_level2 =  ifelse(
      variable < x60, 
        ((variable - 0)/(x60 - 0)) * 0.6, 
        ((variable - x60)/(x100 - x60)) * (1 - 0.6) + 0.6),
    # truncate
    indicator_level2 = case_when(
      indicator_level2 > 1 ~ 1,
      indicator_level2 < 0 ~ 0,
      .default = indicator_level2
    )) |>
  # recast into list column
  drop_na(indicator_level2) |>
  group_by(greg_ID, region) |>
  summarise(indicator_dist_level2 = list(indicator_level2), .groups = "drop")

# we then paste these distributions back into the greg object

greg <- greg |>
  as_tibble() |>
  # simplify datafra by removing some columns...
  select(-glacierAreaCurrent_dist,
         -glacierAreaOld_dist,
         -GID_0,
         -NAME_0) |>
  # add the probability distribution of indicator values
  left_join(
    greg_temp |> select(-region),
    by = join_by(greg_ID)
  ) |>  
  # summarise the distribution
  rowwise() |>
  mutate(
    indicator_level2 = ifelse(
      !is.null(indicator_dist_level2),
      median(unlist(indicator_dist_level2)),
      NA),
  # add first and third quartile
    indicator_Q1_level2 = ifelse(
      !is.null(indicator_dist_level2),
      quantile(unlist(indicator_dist_level2), probs = 0.25),
      NA), 
    indicator_Q3_level2 = ifelse(
      !is.null(indicator_dist_level2),
      quantile(unlist(indicator_dist_level2), probs = 0.75),
      NA), 
  ) |>
  st_as_sf()

```

```{r tbl-gregAgg}
#| tbl-cap: 'Table with indicator values and quartiles for geographical regions.'


DT::datatable(greg |>
  as_tibble() |>
  mutate(across(where(is.numeric), ~ round(.x, digits = 2))) |>
  select(
    greg_ID,
    region,
    #glacierAreaCurrent,
    #X100 = glacierAreaOld,
    #mountainArea,
    indicator,
    indicator_mtArea,
    indicator_level2
  ))
```

```{r}
#| eval: false
threeRidge <- greg_temp |>
  unnest_longer(indicator_dist_level2) |>
  ggplot(aes(x = indicator_dist_level2,
             y = region)) +
  geom_density_ridges(
         fill = "orchid1",
         bandwidth = bw) +
  labs(y = "",
       x = "Indicator values (alternative EA approach)") +
  xlim(.55, 1)

ggpubr::ggarrange(oneRidge, twoRidge, threeRidge, 
                  ncol=1, labels = "auto") 
ggsave(paste0(path, "/img/ridge.png"))
```


@fig-ridgde1 and @tbl-gregAgg show how the weighting by the mountain area of each EA generally reduces the indicator value,
especially Midt-Norge (central Norway), where one EA (indicator value about 0.3)
had very little (but not zero) glaciers to begin with (little weight in pane a), 
but a lot of mountain area (high weight in pane b).
We also see how _preaggregating_ to geographical regions creates more unimodal probability distributions (pane C).

```{r fig-ridgde1}
#| echo: false
#| fig-cap: 'Probability distributions for indicator values aggregated to the scale of geographical regions. a) is aggregated from the original EAs using a weighting based on the initial glacial area. b) uses a weighting based on total mountain area in each EA. c) Uses geographical regions as alternative EAs.'

knitr::include_graphics(paste0(path, "/img/ridge.png"))
```

### 9.4 Aggregating to EAA

Then we aggregate the reginal probability distributions to the entire ecosystem accounting area (EAA), 
which is mainland Norway.

```{r tblEAAAgg}
#| code-fold: true
#| code-summary: "Aggregate indicator values from regions to EAA"

# In order to control the n for how many samples we draw,
# we first calculate the summed area of glaciers

#greg |>
#  as_tibble() |>
#  summarise(total_m2 = sum(glacierAreaOld, na.rm=T)) |> 
#  pull(total_m2)
## Resul: 33 327 254 334. We can divide this by 10^5


greg_to_EAA <- ungroup(greg) |>
  group_by(greg_ID, region) |>
  # sample with weights
  reframe(
    indicator = 
      list(
        sample(
          unlist(indicator_dist),
          size = glacierAreaOld*10^-5,
          replace = T)),
    indicator_mtArea = 
      list(
        sample(
          unlist(indicator_mtArea_dist),
          size = glacierAreaOld*10^-5,
          replace = T)),
    indicator_level2 = 
      list(
        sample(
          unlist(indicator_dist_level2),
          size = glacierAreaOld*10^-5,
          replace = T))
  ) |>
  # concactenate the weighted samples
  ungroup() |>
  summarise(indicator = list(unlist(indicator)),
            indicator_mtArea = list(unlist(indicator_mtArea)),
            indicator_level2 = list(unlist(indicator_level2))) |>
  pivot_longer(everything(),
               names_to = "Indicator_variant",
               values_to = "prob_dist") |>
  # get summary values
  rowwise() |>
  mutate(
    indicator_value = median(unlist(prob_dist)),
  # add first and third quartile
    indicator_Q1 = quantile(unlist(prob_dist), probs = 0.25), 
    indicator_Q3 = quantile(unlist(prob_dist), probs = 0.75))
  


```

### 9.5 Alternative EA (EAA)

Similar to in @sec-ea2 I will see what happens if I estimate the indicator value directly at the EAA level.

```{r}
#| code-fold: true
#| code-summary: "Replace glacier estimates with probability distributions"

EAA <- EAA |>
# adding 3% uncertainty
  rowwise() |>
  mutate(
    glacierAreaCurrent_dist = 
      if_else(!is.na(glacierAreaCurrent),
              list(rnorm(1000, glacierAreaCurrent, glacierAreaCurrent*0.03)),
              NA), 
    glacierAreaOld_dist = 
      if_else(!is.na(glacierAreaOld),
              list(rnorm(1000, glacierAreaOld, glacierAreaOld*0.03)),
              NA))
```

```{r tbl-NormaliseEAA}
#| tbl-cap: 'Indicator values (four approaches) aggregated to the EAA level.'
#| code-fold: true
#| code-summary: "Estimate indicator directly at EAA level"

# create a temporary dataframe
EAA_temp <- EAA |>
  as_tibble() |>
  # unlist and create new rows for each random pair of current and old glacier area estimate
  unnest_longer(c(
    glacierAreaCurrent_dist,
    glacierAreaOld_dist), 
    keep_empty = T) |>
  rename(variable = glacierAreaCurrent_dist, 
         x100 = glacierAreaOld_dist) |>
  mutate(
    # define x60 value
    x60 = x100*0.1,
    # normalise using piecewise linear transfomation
    indicator_level3 =  ifelse(
      variable < x60, 
        ((variable - 0)/(x60 - 0)) * 0.6, 
        ((variable - x60)/(x100 - x60)) * (1 - 0.6) + 0.6),
    # truncate
    indicator_level3 = case_when(
      indicator_level3 > 1 ~ 1,
      indicator_level3 < 0 ~ 0,
      .default = indicator_level3
    )) |>
  # recast into list column
  group_by(EAA_ID) |>
  summarise(prob_dist = list(indicator_level3), .groups = "drop") |>
  add_column(Indicator_variant = "indicator_level3") |>
  # get summary values
  rowwise() |>
  mutate(
    indicator_value = median(unlist(prob_dist)),
  # add first and third quartile
    indicator_Q1 = quantile(unlist(prob_dist), probs = 0.25), 
    indicator_Q3 = quantile(unlist(prob_dist), probs = 0.75))

# combine with the eariler dataset
greg_to_EAA <- greg_to_EAA |>
  bind_rows(EAA_temp)

DT::datatable(greg_to_EAA |>
  mutate(across(where(is.numeric), ~ round(.x, digits = 2))) |>
  select(
    -prob_dist,
    -EAA_ID
  ))

```

```{r fig-eaaRidge}
#| fig.cap: 'Distribution of indicator values for the EAA leel using four alternative aggregation pathways. Lines are quantiles.'
greg_to_EAA |>
  unnest_longer(prob_dist) |>
  ggplot(aes(x = prob_dist,
             y = Indicator_variant,
             fill = Indicator_variant)) +
  geom_density_ridges(
         bandwidth = bw,
         alpha = .6,
         quantile_lines = T,
         show.legend = F) +
  labs(y = "",
       x = "Indicator values") +
  xlim(.55, 1)

```

## 10. Results

@tbl-NormaliseEAA and @fig-eaaRidge show the indicator estaimates and distributions for the EAA level.
I recomend using the _indicator_, i.e. the 
indicator version using the aggregation pathway 

$$
sp.agg^1^ - [scale - transform - truncate] - sp-agg^2^ - sp.agg^3^
$$ 

where ^1^ refers to the summation of glacial area inside each EA (_pre-aggregation_); 
^2^ refers to aggregation to geographical region using weighted sampling and taking the median from the resulting distribution; 
and ^3^ refers to further aggregation to the EAA, 
also using weighted sampling from the probability 
distribution of indicator values for the geographical region level.


@fig-maps show that at least three of the aggregation shemes are qualitatively similar, but not identical.

```{r}
#| message: false
#| eval: false

# add indicator data to EAA 
EAA <- EAA |>
  ungroup() |>
  as_tibble() |>
  left_join(greg_to_EAA |>
              mutate(EAA_ID = "1"),
            by = join_by(EAA_ID)) |>
  st_as_sf()

# prepare the greg data a little to ba able to row bind with the others
temp <- greg |>
  pivot_longer(cols = c(
    indicator,
    indicator_level2,
    indicator_mtArea
  ),
  names_to = "Indicator_variant",
  values_to = "indicator_value") |>
  select(
    region,
    Indicator_variant,
    indicator_value
  )

# function for renaming geomatry column in sf
rename_geometry <- function(g, name){
    current = attr(g, "sf_column")
    names(g)[names(g)==current] = name
    st_geometry(g)=name
    g
}

one <- EA |>
  rename(indicator_value = indicator) |>
  add_column(level = 1,
             Indicator_variant = "indicator") |>
  select(indicator_value,
         level,
         Indicator_variant)
one <- rename_geometry(one, "geometry")

two <-  EAA |> 
    add_column(level = 3) |>
    select(indicator_value,
         level,
         Indicator_variant)

three <- temp |> 
    add_column(level = 2) |>
    select(indicator_value,
         level,
         Indicator_variant)

plotdat <- rbind(
  one, two, three
)


plotdat |>
  ggplot() +
  geom_sf(aes(fill = indicator_value),
          colour = NA) +
  facet_grid(rows = vars(level),
             cols = vars(Indicator_variant),
             drop = T) +
  scale_fill_gradient(na.value = "grey80") +
  #geom_sf(data = EAA, fill = NA) +
  theme_bw()

ggsave(paste0(path, "/img/allmaps.png"))
```

```{r fig-maps}
#| fig-cap: 'Indicator estimates (median of probability distributions) at three spatial levels: EA level (top row); geographical region (second row); ecosystem accounting area (bottom row). The two latter aggregation levels are represnted with several approaches. _Indicator_ and _indicator_mtArea_ relies on data aggregated through the EA level, but _indicator_mtArea_ uses total mountain area, rather than initial glacier area, as the area weight during the aggregation. _Indicator level2_ refers to the approach where indicator values were estimated directly at the level of geographical regions, and _indicator_level3_ was estimated directly at the EAA level.'
knitr::include_graphics(paste0(path, "/img/allmaps.png"))
```

The final output is then the indicator estimate for the EAA level (@tbl-finalTable).

```{r tbl-finalTable}
#| include: false
#| tbl-cap: 'Indicator values for NO_GLA_001 aggregated to EAA level'

greg_to_EAA |>
  filter(Indicator_variant == "indicator") |>
  mutate(across(where(is.numeric), ~ round(.x, digits = 2))) |>
  select(
    -prob_dist,
    -EAA_ID,
    -Indicator_variant
  ) |>
  add_column(
    Indicator = "Glacier area",
    Indicator_ID = "NO_GLAC_001",
    Ecosystem = "Alpine",
    Area = "Mainland Norway",
    .before = "indicator_value"
  ) |>
  rename(Q1 = indicator_Q1,
         Q3 = indicator_Q3) |>
  DT::datatable()
```
